{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def get_action(state, w): # w := parameter vector\n",
    "    if state.dot(w) > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def play_one_episode(env, params):\n",
    "    observation = env.reset()\n",
    "    done = False\n",
    "    t = 0 # tracks how many steps are completed\n",
    "    r = 0 # tracks the reward\n",
    "    max_nb_steps = 10000\n",
    "\n",
    "    while not done and t < max_nb_steps:\n",
    "        t += 1\n",
    "        action = get_action(observation, params)\n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "        r += reward\n",
    "\n",
    "    return r\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def play_multiple_episodes(env, T, params):\n",
    "    episode_rewards = []\n",
    "\n",
    "    for i in range(T):\n",
    "        episode_rewards[i] = play_one_episode(env, params)\n",
    "\n",
    "    avg_reward = episode_rewards.mean()\n",
    "    print(\"average reward: \", avg_reward)\n",
    "    return avg_reward\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def random_search(env):\n",
    "    episode_rewards = []\n",
    "    best = 0\n",
    "    params = None\n",
    "\n",
    "    for t in range(100):\n",
    "        new_params = np.random.random(4)*2 - 1\n",
    "        # this code imitate the cart pole game, 4 stands for the states in cartpole and the policy represents the dot #product\n",
    "        avg_reward = play_multiple_episodes(env, 100, new_params)\n",
    "        episode_rewards.append(avg_reward)\n",
    "\n",
    "        if avg_reward > best:\n",
    "            params = new_params\n",
    "            best = avg_reward\n",
    "\n",
    "    return episode_rewards, params"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'dot'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[1;32mIn [7]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m      2\u001B[0m     env \u001B[38;5;241m=\u001B[39m gym\u001B[38;5;241m.\u001B[39mmake(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCartPole-v1\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m----> 3\u001B[0m     episode_rewards, params \u001B[38;5;241m=\u001B[39m \u001B[43mrandom_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43menv\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m     plt\u001B[38;5;241m.\u001B[39mplot(episode_rewards)\n\u001B[0;32m      5\u001B[0m     plt\u001B[38;5;241m.\u001B[39mshow()\n",
      "Input \u001B[1;32mIn [5]\u001B[0m, in \u001B[0;36mrandom_search\u001B[1;34m(env)\u001B[0m\n\u001B[0;32m      7\u001B[0m new_params \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39mrandom(\u001B[38;5;241m4\u001B[39m)\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m2\u001B[39m \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;66;03m# this code imitate the cart pole game, 4 stands for the states in cartpole and the policy represents the dot #product\u001B[39;00m\n\u001B[1;32m----> 9\u001B[0m avg_reward \u001B[38;5;241m=\u001B[39m \u001B[43mplay_multiple_episodes\u001B[49m\u001B[43m(\u001B[49m\u001B[43menv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnew_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     10\u001B[0m episode_rewards\u001B[38;5;241m.\u001B[39mappend(avg_reward)\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m avg_reward \u001B[38;5;241m>\u001B[39m best:\n",
      "Input \u001B[1;32mIn [4]\u001B[0m, in \u001B[0;36mplay_multiple_episodes\u001B[1;34m(env, T, params)\u001B[0m\n\u001B[0;32m      2\u001B[0m episode_rewards \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(T):\n\u001B[1;32m----> 5\u001B[0m     episode_rewards[i] \u001B[38;5;241m=\u001B[39m \u001B[43mplay_one_episode\u001B[49m\u001B[43m(\u001B[49m\u001B[43menv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      7\u001B[0m avg_reward \u001B[38;5;241m=\u001B[39m episode_rewards\u001B[38;5;241m.\u001B[39mmean()\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124maverage reward: \u001B[39m\u001B[38;5;124m\"\u001B[39m, avg_reward)\n",
      "Input \u001B[1;32mIn [3]\u001B[0m, in \u001B[0;36mplay_one_episode\u001B[1;34m(env, params)\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m done \u001B[38;5;129;01mand\u001B[39;00m t \u001B[38;5;241m<\u001B[39m max_nb_steps:\n\u001B[0;32m      9\u001B[0m     t \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m---> 10\u001B[0m     action \u001B[38;5;241m=\u001B[39m \u001B[43mget_action\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobservation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     11\u001B[0m     observation, reward, terminated, truncated, info \u001B[38;5;241m=\u001B[39m env\u001B[38;5;241m.\u001B[39mstep(action)\n\u001B[0;32m     12\u001B[0m     r \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m reward\n",
      "Input \u001B[1;32mIn [2]\u001B[0m, in \u001B[0;36mget_action\u001B[1;34m(state, w)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_action\u001B[39m(state, w):\n\u001B[1;32m----> 2\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mstate\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdot\u001B[49m(w) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m      3\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m      4\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'tuple' object has no attribute 'dot'"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    env = gym.make('CartPole-v1')\n",
    "    episode_rewards, params = random_search(env)\n",
    "    plt.plot(episode_rewards)\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Final run with final weights: \")\n",
    "    play_multiple_episodes(env, 100, params)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}